{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../sensor_data/'\n",
    "users = ['s1621503',\n",
    " 's1746788',\n",
    " 's1701688',\n",
    " 's1710228',\n",
    " 's1721039',\n",
    " 's1616573',\n",
    " 's1758009',\n",
    " 's1660711']\n",
    "full_paths = [data_path + usr + '/' + filename for usr in users for filename in os.listdir(data_path + usr)]\n",
    "header_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class to store recording data - and info about location and activity type\n",
    "class DataRecording:  \n",
    "    def __init__(self, sensor_position, sensor_side, activity, activity_id):\n",
    "        self.sensor_position = sensor_position\n",
    "        self.sensor_side = sensor_side\n",
    "        self.activity = activity\n",
    "        self.activity_id = activity_id\n",
    "    \n",
    "    @classmethod\n",
    "    def create_recording(cls, filepath):\n",
    "        with open(filepath) as f:\n",
    "            head = [next(f).rstrip().split('# ')[1].split(':')[1].strip() for x in range(header_size)]\n",
    "            recording = DataRecording(head[0], head[1], head[2], head[3])\n",
    "        df = pd.read_csv(filepath, header=5)\n",
    "        recording.data = df[['accel_x', 'accel_y', 'accel_z']]\n",
    "        return recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../sensor_data/s1721039/.DS_Store\n",
      "../sensor_data/s1721039/list.txt\n",
      "../sensor_data/s1721039/PDIoT Data Collection Protocol.docx\n",
      "../sensor_data/s1721039/my_copy.sh\n"
     ]
    }
   ],
   "source": [
    "# read all files into a DataRecording \n",
    "all_data = [] # all DataRecordings\n",
    "for path in full_paths:\n",
    "    try:\n",
    "        all_data.append(DataRecording.create_recording(path))\n",
    "    except:\n",
    "        pass\n",
    "        print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activities selected for classification\n",
    "allowed_activites = ['Climbing stairs', 'Descending stairs', 'Walking at normal speed', 'Running', 'Standing']\n",
    "def get_activity_id(activity):\n",
    "    return allowed_activites.index(activity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accel_x</th>\n",
       "      <th>accel_y</th>\n",
       "      <th>accel_z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.347168</td>\n",
       "      <td>-0.996155</td>\n",
       "      <td>0.004822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.339600</td>\n",
       "      <td>-0.986877</td>\n",
       "      <td>0.061218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.216797</td>\n",
       "      <td>-1.018127</td>\n",
       "      <td>0.129089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.149902</td>\n",
       "      <td>-0.910950</td>\n",
       "      <td>-0.038879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.267090</td>\n",
       "      <td>-0.824036</td>\n",
       "      <td>0.064636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>-0.219727</td>\n",
       "      <td>-0.969543</td>\n",
       "      <td>-0.039368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>-0.219971</td>\n",
       "      <td>-0.976868</td>\n",
       "      <td>-0.067932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>-0.140869</td>\n",
       "      <td>-0.978088</td>\n",
       "      <td>-0.158997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>-0.122314</td>\n",
       "      <td>-1.065491</td>\n",
       "      <td>-0.265930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>-0.290527</td>\n",
       "      <td>-1.146790</td>\n",
       "      <td>-0.297913</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>288 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      accel_x   accel_y   accel_z\n",
       "0   -0.347168 -0.996155  0.004822\n",
       "1   -0.339600 -0.986877  0.061218\n",
       "2   -0.216797 -1.018127  0.129089\n",
       "3   -0.149902 -0.910950 -0.038879\n",
       "4   -0.267090 -0.824036  0.064636\n",
       "..        ...       ...       ...\n",
       "283 -0.219727 -0.969543 -0.039368\n",
       "284 -0.219971 -0.976868 -0.067932\n",
       "285 -0.140869 -0.978088 -0.158997\n",
       "286 -0.122314 -1.065491 -0.265930\n",
       "287 -0.290527 -1.146790 -0.297913\n",
       "\n",
       "[288 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select only allowed activities from right front pocket\n",
    "right_pocket_data = [x for x in all_data if \n",
    "                        x.sensor_position == 'Front pocket (trouser)' \n",
    "                            and \n",
    "                        x.sensor_side == 'Right'\n",
    "                           and\n",
    "                        x.activity in allowed_activites\n",
    "                       ]\n",
    "right_pocket_data[0].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to return all overlapping windows from a dataframe\n",
    "# input a 2D nxm dataframe\n",
    "# output y x win_size x m - where y in the number of windows\n",
    "def get_overlapping_windows(df, win_size, overlap):\n",
    "    rows  = df.shape[0]\n",
    "    assert(overlap < 1)\n",
    "    assert(overlap >= 0)\n",
    "    assert(win_size <= rows)\n",
    "\n",
    "    increment = int(win_size * (1 - overlap))\n",
    "    result = []\n",
    "    for i in range(0, rows - win_size, increment):\n",
    "        feature_vector = df[i:i+win_size]\n",
    "        result.append(feature_vector)\n",
    "    return np.array(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataset\n",
    "# each row is a window of window x 3 of x, y, z acceleration data\n",
    "# y corresponds to activity_id\n",
    "def create_dataset(data_objects, win_size, overlap):\n",
    "    X = None\n",
    "    y = None\n",
    "    for d_o in data_objects:\n",
    "        windows = get_overlapping_windows(d_o.data, win_size, overlap)\n",
    "        \n",
    "        # create DataSet\n",
    "        if X is None:\n",
    "            X = windows\n",
    "        else:\n",
    "            X = np.vstack((X, windows))\n",
    "        \n",
    "        # Create Labels\n",
    "        if y is None:\n",
    "            y = np.repeat(get_activity_id(d_o.activity), windows.shape[0])\n",
    "        else:\n",
    "            ys = np.repeat(get_activity_id(d_o.activity), windows.shape[0])\n",
    "            y = np.concatenate((y, ys))\n",
    " \n",
    "    \n",
    "    return X, y\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataset\n",
    "X, y = create_dataset(right_pocket_data, 50, 0.5)\n",
    "y = tf.keras.utils.to_categorical(y, num_classes=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_timesteps, n_features, n_outputs = X.shape[1], X.shape[2], y.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit and evaluate a model\n",
    "def evaluate_model(trainX, trainy, testX, testy):\n",
    "    verbose, epochs, batch_size = 0, 10, 32\n",
    "    n_timesteps, n_features, n_outputs = trainX.shape[1], trainX.shape[2], trainy.shape[1]\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(n_timesteps,n_features)))\n",
    "    model.add(layers.Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.MaxPooling1D(pool_size=2))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(100, activation='relu'))\n",
    "    model.add(layers.Dense(n_outputs, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    # fit network\n",
    "    model.fit(trainX, trainy, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "    # evaluate model\n",
    "    _, accuracy = model.evaluate(testX, testy, batch_size=batch_size, verbose=0)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create test and train sets\n",
    "indices = np.random.permutation(X.shape[0])\n",
    "boundary = int(X.shape[0] * 0.8)\n",
    "train_idx, test_idx = indices[:boundary], indices[boundary:]\n",
    "Xtrain, Ytrain, Xtest, Ytest = X[train_idx,:], y[train_idx,:], X[test_idx,:], y[test_idx,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'evaluate_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c26787ad4e95>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'evaluate_model' is not defined"
     ]
    }
   ],
   "source": [
    "score = evaluate_model(Xtrain, Ytrain, Xtest, Ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model as tflite\n",
    "def save_tflite_model(model):\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    tflite_model = converter.convert()\n",
    "    with open('model.tflite', 'wb') as f:\n",
    "        f.write(tflite_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
